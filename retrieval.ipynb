{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6375cf02-c0ae-4fc9-ad53-b21a8e5478fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "\n",
    "env = {}\n",
    "\n",
    "# read .env file and set variables\n",
    "with open('.env') as f:\n",
    "    for line in f:\n",
    "        key, value = line.strip().split('=')\n",
    "        env[key] = value\n",
    "\n",
    "openai.api_key = env['OPEN_AI_KEY']\n",
    "OPENAI_API_KEY = env['OPEN_AI_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b7ca85-ff39-41ec-85c1-bf5a00f9f8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lark\n",
      "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Downloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lark\n",
      "Successfully installed lark-1.1.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf202a2-6623-4c06-b31f-0d963e624c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b176433-c41b-47ef-8a42-faabb5c9ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(openai_api_key=env['OPEN_AI_KEY'])\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919888a2-b36d-426a-a447-95af846acd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b848c8a-af2d-4f9a-92ea-b956bb544d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab743d0-00df-4eea-9a80-9706c81c4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab7d8fa5-02cc-457f-8684-8fbba08adbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f14249da-ed71-4fb5-b7f8-6934b85fa6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c2ae523-f454-4add-ae6a-c385aa217d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d5bac33-6f71-46df-a7cf-92f2db9b3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7b411f-48b4-4441-b340-a7a6e6cc4ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Octave Tutorial \\nComputing on data \\nMachine Learning'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "128b878d-9d67-46c3-9f94-5259a42703ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Octave Tutorial \\nVectorial implementation \\nMachine Learning'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa06ad73-27df-4b10-b509-562d88ef586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2888d45-69ef-43d9-a17e-18e5efbf4ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Octave Tutorial \\nComputing on data \\nMachine Learning'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae55b3c-973a-4589-b5f8-d0af7e83766f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andrew\\t\\r \\xa0Ng\\t\\r \\xa0Matrix\\t\\r \\xa0Addi4on'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19eafed2-c207-4c9b-8133-e73d95f140a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d56dcfd1-6b82-4835-bbce-cb03e305b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/Lecture3.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba482ca6-dc09-4557-b31e-31e4f17242e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 18, 'source': 'docs/Lecture3.pdf'}\n",
      "{'page': 0, 'source': 'docs/Lecture3.pdf'}\n",
      "{'page': 8, 'source': 'docs/Lecture3.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db597bb5-be3f-47f8-bfc0-8b5146baa6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "908cacc9-0ff6-463c-9d08-1f22e2f6de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/Lecture1.pdf`, `docs/Lecture2.pdf`, or `docs/Lecture3.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98d9e4d5-5a80-48b9-866b-caf8a90df59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langchain-openai) (0.2.11)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langchain-openai) (1.35.9)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.83)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.8.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.2)\n",
      "Downloading langchain_openai-0.1.14-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-openai\n",
      "Successfully installed langchain-openai-0.1.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9b3efa5-0df5-4df5-a0d7-1c18c9f23c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35eb46cf-22e0-44a4-a5c6-9d79b02bafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0, openai_api_key=env['OPEN_AI_KEY'])\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bfee3e7-f58b-4afc-a362-c47f7ee9daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa786833-1d82-4de3-b1d6-599a4ea03940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c193f1b1-0d5b-42a2-95a1-0562b503a0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': 'docs/Lecture3.pdf'}\n",
      "{'page': 22, 'source': 'docs/Lecture3.pdf'}\n",
      "{'page': 18, 'source': 'docs/Lecture3.pdf'}\n",
      "{'page': 8, 'source': 'docs/Lecture3.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "996099e1-af4a-4974-b753-791f116c62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "127f94c5-9ec5-4291-b8c1-af9fa260ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08af6a62-ee7a-46c5-8fd1-e94597e3530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\", openai_api_key=env['OPEN_AI_KEY'])\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60e05023-5755-4870-8dc9-bfdf1fa65863",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50fc7b6f-2db6-454f-93a9-4b695b498eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Machine Learning\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Machine Learning\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c240752-6374-455b-b628-1d0b82ef6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d9c6ae9-de5f-4d3e-b389-3dbe26e6a0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Machine Learning\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c8d2c38-39b1-4042-ab38-08c600226a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47230d82-7d6c-4a42-8cb9-a66c23e28164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"docs/Lecture1.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9d3989b-ad40-4819-b65c-a444c344b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/pikkuaapo/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp311-cp311-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5eccef8c-93c0-4676-bb79-2ad1812d1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "271ace00-c2d5-4d0b-8b3d-55befa9552f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Astronomical data analysis Market segmentation \\n Andrew NgCocktail party problem \\nMicrophone #1 \\nMicrophone #2 Speaker #1 \\nSpeaker #2 \\n Andrew Ng [Audio clips courtesy of Te-Won Lee.] Microphone #1: Microphone #2: Microphone #1: Microphone #2: Output #1: Output #2: \\nOutput #1: Output #2: \\n Andrew NgCocktail party problem algorithm \\n[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)* x'); \\n[Source: Sam Roweis, Yair Weiss & Eero Simoncelli] Of the following examples, which would you address using an \\nunsupervised learning algorithm?  (Check all that ap ply.) \\nGiven a database of customer data, automatically di scover market \\nsegments and group customers into different market segments. Given email labeled as spam/not spam, learn a spam filter. \\nGiven a set of news articles found on the web, grou p them into \\nset of articles about the same story. Given a dataset of patients diagnosed as either hav ing diabetes or \\nnot, learn to classify new patients as having diabe tes or not.  Andrew Ng\")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16577ad3-3dab-4c93-a853-f8a9d6618bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='spam.  What is the task T in this setting? “A computer program is said to learn from experience E with respect to \\nsome task T and some performance measure P , if its performance on T, \\nas measured by P , improves with experience E.” \\n Classifying emails as spam or not spam. Watching you label emails as spam or not spam. The number (or fraction) of emails correctly classi fied as spam/not spam. \\nNone of the above—this is not a machine learning pr oblem. Suppose your email program watches which emails you  do or do \\nnot mark as spam, and based on that learns how to b etter filter \\nspam.  What is the task T in this setting? “A computer program is said to learn from experience E with respect to \\nsome task T and some performance measure P , if its performance on T, \\nas measured by P , improves with experience E.”  Andrew NgMachine learning algorithms: - Supervised learning - Unsupervised learning Others: Reinforcement learning, recommender \\nsystems. \\nAlso talk about: Practical advice for applying \\nlearning algorithms.  Andrew Ng Andrew NgIntroduction \\nSupervised Learning \\nMachine Learning  Andrew Ng0100 200 300 400 \\n0 500 1000 1500 2000 2500 Housing price prediction. \\nPrice ($) in 1000’s \\nSize in feet 2\\nRegression: Predict continuous \\nvalued output (price) Supervised Learning \\n“right answers” given  Andrew NgBreast cancer (malignant, benign) \\nClassification \\nDiscrete valued output (0 or 1) \\nMalignant? 1(Y) \\n0(N)')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a8bd7-059b-4dc3-9386-4ef36d90d78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
